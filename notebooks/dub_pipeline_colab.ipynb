{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "gpuType": "T4"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üé¨ Supernan ‚Äì Hindi Video Dubbing Pipeline\n",
    "\n",
    "**End-to-end pipeline: English Video ‚Üí Hindi Dubbed Video with Voice Cloning + Lip Sync**\n",
    "\n",
    "Stages:\n",
    "1. Extract 15-second segment (ffmpeg)\n",
    "2. Transcribe English speech (Whisper)\n",
    "3. Translate to Hindi (Helsinki-NLP)\n",
    "4. Synthesize Hindi voices with voice cloning (Coqui XTTS v2)\n",
    "5. Sync audio durations (ffmpeg atempo)\n",
    "6. Lip-sync video to Hindi audio (Wav2Lip)\n",
    "7. Restore face quality (GFPGAN)\n",
    "\n",
    "**Cost: ‚Çπ0 (Google Colab Free Tier T4 GPU)**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚úÖ Step 0: Check GPU"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "!nvidia-smi --query-gpu=name,memory.total,memory.free --format=csv\n",
    "import torch\n",
    "print(f'PyTorch: {torch.__version__}')\n",
    "print(f'CUDA available: {torch.cuda.is_available()}')\n",
    "if torch.cuda.is_available():\n",
    "    print(f'GPU: {torch.cuda.get_device_name(0)}')"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üì¶ Step 1: Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Install system packages\n",
    "!apt-get update -qq\n",
    "!apt-get install -y -qq ffmpeg git libsndfile1\n",
    "print('System packages installed ‚úì')"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Install Python packages (this takes ~3-5 minutes on first run)\n",
    "!pip install openai-whisper transformers sentencepiece sacremoses -q\n",
    "!pip install TTS -q\n",
    "!pip install librosa soundfile pydub -q\n",
    "!pip install basicsr facexlib realesrgan -q\n",
    "!pip install opencv-python-headless -q\n",
    "print('Python packages installed ‚úì')"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìÇ Step 2: Clone Pipeline Repository"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import os\n",
    "\n",
    "# ‚ö†Ô∏è Replace with your actual GitHub repo URL after pushing\n",
    "REPO_URL = 'https://github.com/YOUR_USERNAME/supernan-hindi-dubbing.git'\n",
    "REPO_DIR = '/content/supernan-hindi-dubbing'\n",
    "\n",
    "if not os.path.isdir(REPO_DIR):\n",
    "    !git clone {REPO_URL} {REPO_DIR}\n",
    "    print('Repo cloned ‚úì')\n",
    "else:\n",
    "    !cd {REPO_DIR} && git pull\n",
    "    print('Repo updated ‚úì')\n",
    "\n",
    "os.chdir(REPO_DIR)\n",
    "print(f'Working directory: {os.getcwd()}')"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üé• Step 3: Upload Source Video\n",
    "\n",
    "Upload your video file to Colab or download it from Google Drive."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Option A: Upload manually\n",
    "from google.colab import files\n",
    "uploaded = files.upload()\n",
    "VIDEO_PATH = list(uploaded.keys())[0]\n",
    "print(f'Uploaded: {VIDEO_PATH}')"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Option B: Download from Google Drive using gdown\n",
    "# !pip install gdown -q\n",
    "# FILE_ID = '1urRXU3HGjL30lXxQakqK_5rVjbH9XW3O'  # Supernan training video ID\n",
    "# !gdown https://drive.google.com/uc?id={FILE_ID} -O /content/supernan_video.mp4\n",
    "# VIDEO_PATH = '/content/supernan_video.mp4'"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚öôÔ∏è Step 4: Configure Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Pipeline configuration\n",
    "SEGMENT_START = 15    # seconds\n",
    "SEGMENT_END   = 30    # seconds\n",
    "WHISPER_MODEL = 'small'  # 'base' for CPU, 'small'/'medium' for T4\n",
    "ENABLE_FACE_RESTORE = True\n",
    "\n",
    "print(f'Processing: {SEGMENT_START}s ‚Üí {SEGMENT_END}s ({SEGMENT_END - SEGMENT_START}s clip)')\n",
    "print(f'Whisper model: {WHISPER_MODEL}')\n",
    "print(f'Face restoration: {ENABLE_FACE_RESTORE}')"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üöÄ Step 5: Run Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import subprocess, sys\n",
    "\n",
    "cmd = [\n",
    "    sys.executable, 'dub_video.py',\n",
    "    '--input', VIDEO_PATH,\n",
    "    '--start', str(SEGMENT_START),\n",
    "    '--end',   str(SEGMENT_END),\n",
    "    '--whisper-model', WHISPER_MODEL,\n",
    "    '--output', '/content/final_dubbed.mp4',\n",
    "]\n",
    "\n",
    "if not ENABLE_FACE_RESTORE:\n",
    "    cmd.append('--no-face-restore')\n",
    "\n",
    "print('Running pipeline:', ' '.join(cmd))\n",
    "result = subprocess.run(cmd, check=True)\n",
    "print('\\n‚úÖ Pipeline complete!')"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üé¨ Step 6: Preview Output"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from IPython.display import Video, display\n",
    "import os\n",
    "\n",
    "output_file = '/content/final_dubbed.mp4'\n",
    "\n",
    "if os.path.isfile(output_file):\n",
    "    size_mb = os.path.getsize(output_file) / (1024 * 1024)\n",
    "    print(f'Output file: {output_file} ({size_mb:.2f} MB)')\n",
    "    display(Video(output_file, embed=True, width=640))\n",
    "else:\n",
    "    print('ERROR: Output file not found. Check pipeline logs above.')"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üíæ Step 7: Download Output"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from google.colab import files\n",
    "files.download('/content/final_dubbed.mp4')"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## üîß Advanced: Run Individual Stages for Debugging"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Stage 1: Test extraction only\n",
    "import sys\n",
    "sys.path.insert(0, REPO_DIR)\n",
    "from modules.extractor import extract_segment, extract_speaker_ref\n",
    "\n",
    "vid, aud = extract_segment(VIDEO_PATH, start_sec=15, end_sec=30)\n",
    "ref = extract_speaker_ref(aud)\n",
    "print(f'Video clip: {vid}')\n",
    "print(f'Audio clip: {aud}')\n",
    "print(f'Speaker ref: {ref}')"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Stage 2: Transcribe and display\n",
    "from modules.transcriber import transcribe_audio\n",
    "segments = transcribe_audio(aud, model_size='base')\n",
    "\n",
    "print('Transcription:')\n",
    "for seg in segments:\n",
    "    print(f'  [{seg[\"start\"]:.2f} ‚Üí {seg[\"end\"]:.2f}] {seg[\"text\"]}')"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Stage 3: Translate and display\n",
    "from modules.translator import translate_segments\n",
    "segments = translate_segments(segments)\n",
    "\n",
    "print('Translation:')\n",
    "for seg in segments:\n",
    "    print(f'  EN: {seg[\"text\"]}')\n",
    "    print(f'  HI: {seg.get(\"hindi_text\", \"\")}\\n')"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## üìä Pipeline Timing Breakdown"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "\n",
    "timing_data = {\n",
    "    'Stage': ['Extract (ffmpeg)', 'Transcribe (Whisper small)', 'Translate (Helsinki-NLP)', \n",
    "              'TTS (XTTS v2, GPU)', 'Audio Sync (ffmpeg)', 'Lip Sync (Wav2Lip GAN)', 'Face Restore (GFPGAN)'],\n",
    "    'Est. Time (15s clip)': ['~2s', '~8s', '~3s', '~20s', '~2s', '~90s', '~60s'],\n",
    "    'GPU Required': ['No', 'Optional', 'No', 'Recommended', 'No', 'Yes (strongly)', 'Recommended'],\n",
    "    'Cost': ['‚Çπ0', '‚Çπ0', '‚Çπ0', '‚Çπ0', '‚Çπ0', '‚Çπ0', '‚Çπ0'],\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(timing_data)\n",
    "df"
   ],
   "execution_count": null,
   "outputs": []
  }
 ]
}
